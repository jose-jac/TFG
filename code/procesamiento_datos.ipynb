{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jabel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jabel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from wordcloud import STOPWORDS\n",
    "from langdetect import detect_langs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv',na_values=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos texto y titulo en text, sabiendo que a veces uno de los dos es null\n",
    "df['text'] = df['text'].fillna('') + ' ' + df['title'].fillna('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de Lenguajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para descartar noticias que no estén en inglés con langdetect \n",
    "def detectar_idioma_principal(text):\n",
    "\ttry:\n",
    "\t\treturn detect_langs(\" \".join(text.split()[:50]))[0].lang\n",
    "\texcept:\n",
    "\t\treturn False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectamos los lenguajes principales de cada noticia\n",
    "df['language'] = df['text'].apply(detectar_idioma_principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticias verdaderas:\n",
      "en    10386\n",
      "fr        1\n",
      "Name: language, dtype: int64\n",
      "Noticias falsas:\n",
      "en       9866\n",
      "ru        156\n",
      "es        142\n",
      "de         96\n",
      "fr         71\n",
      "ar         19\n",
      "pt          9\n",
      "tr          7\n",
      "it          6\n",
      "so          5\n",
      "ro          4\n",
      "hr          4\n",
      "nl          4\n",
      "no          4\n",
      "cy          3\n",
      "da          2\n",
      "el          2\n",
      "hu          1\n",
      "ca          1\n",
      "False       1\n",
      "id          1\n",
      "zh-cn       1\n",
      "sw          1\n",
      "fi          1\n",
      "lt          1\n",
      "tl          1\n",
      "et          1\n",
      "pl          1\n",
      "vi          1\n",
      "sv          1\n",
      "Name: language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vemos cuántas noticias hay de cada lenguaje en noticias verdaderas y falsas\n",
    "print(\"Noticias verdaderas:\")\n",
    "print(df[df['label']==0]['language'].value_counts())\n",
    "print(\"Noticias falsas:\")\n",
    "print(df[df['label']==1]['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartamos las noticias que no están en inglés\n",
    "df = df[df['language']=='en']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar el texto\n",
    "def clean_text(text):\n",
    "\t\n",
    "\t# Estandarizamos caracteres extraños\n",
    "\tif(type(text) == str):\n",
    "\t\ttext = text.replace('“', '\"')\n",
    "\t\ttext = text.replace('”', '\"')\n",
    "\t\ttext = text.replace('’', \"'\")\n",
    "\t\ttext = text.replace('‘', \"'\")\n",
    "\t\ttext = text.replace('`', \"'\")\n",
    "\t\ttext = text.replace('´', \"'\")\n",
    "\t\ttext = text.replace('–', '-')\n",
    "\t\ttext = text.replace('−', '-')\n",
    "\t\ttext = text.replace('…', '...')\n",
    "\t\ttext = text.replace('—', '-')\n",
    "\t\ttext = text.replace('•', '-')\n",
    "\t\ttext = text.replace('·', '-')\n",
    "\t\n",
    "\t\n",
    "    # Eliminar urls\n",
    "\ttext = re.sub(r'http\\S+', ' ', str(text))\n",
    "\t\n",
    " \t# Eliminar emojis\n",
    "\temoji_pattern = re.compile(\"[\"\n",
    "\t\t\tu\"\\U0001F600-\\U0001F64F\"\n",
    "\t\t\tu\"\\U0001F300-\\U0001F5FF\"\n",
    "\t\t\tu\"\\U0001F680-\\U0001F6FF\"\n",
    "\t\t\tu\"\\U0001F1E0-\\U0001F1FF\"\n",
    "\t\t\tu\"\\U00002702-\\U000027B0\"\n",
    "\t\t\tu\"\\U000024C2-\\U0001F251\"\n",
    "\t\t\t\"]+\", flags=re.UNICODE)\n",
    "\ttext = emoji_pattern.sub(r'', text)\n",
    "\t\n",
    " \t# Eliminar palabras con números\n",
    "\ttext = re.sub(r'\\w*\\d\\w*', ' ', text)\n",
    "\t\n",
    "    # Eliminar palabras que no estén en latino\n",
    "\ttext = re.sub(r'[^\\x00-\\x7F]+', ' ', str(text))\n",
    " \n",
    " \t# Eliminar signos de puntuación\n",
    "\ttext = re.sub(r'[^\\w\\s]', ' ', str(text))\n",
    " \n",
    "\t# Eliminar barra baja\n",
    "\ttext = re.sub(r'_', ' ', str(text))\n",
    "\t\n",
    "    # Minusculas\n",
    "\ttext = text.lower()\n",
    " \n",
    " \t# Eliminar contracciones\n",
    "\ttext = re.sub(r\"ain\\'t\", \" am not\", text)\n",
    "\ttext = re.sub(r\"aren\\'t\", \" are not\", text)\n",
    "\ttext = re.sub(r\"can\\'t\", \" can not\", text)\n",
    "\ttext = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
    "\ttext = re.sub(r\"\\'cause\", \" because\t\", text)\n",
    "\ttext = re.sub(r\"could\\'ve\", \" could have\", text)\n",
    "\ttext = re.sub(r\"couldn\\'t\", \" could not\", text)\n",
    "\ttext = re.sub(r\"couldn\\'t've\", \" could not have\", text)\n",
    "\ttext = re.sub(r\"didn\\'t\", \" did not\", text)\n",
    "\ttext = re.sub(r\"doesn\\'t\", \" does not\", text)\n",
    "\ttext = re.sub(r\"don\\'t\", \" do not\", text)\n",
    "\ttext = re.sub(r\"hadn\\'t\", \" had not\", text)\n",
    "\ttext = re.sub(r\"hadn\\'t've\", \" had not have\", text)\n",
    "\ttext = re.sub(r\"hasn\\'t\", \" has not\", text)\n",
    "\ttext = re.sub(r\"haven\\'t\", \" have not\", text)\n",
    "\ttext = re.sub(r\"he\\'d\", \" he had\", text)\n",
    "\ttext = re.sub(r\"he\\'d've\", \" he would have\", text)\n",
    "\ttext = re.sub(r\"he\\'ll\", \" he will\", text)\n",
    "\ttext = re.sub(r\"he\\'ll've\", \" he will have\", text)\n",
    "\ttext = re.sub(r\"he\\'s\", \" he is\", text)\n",
    "\ttext = re.sub(r\"how\\'d\", \" how did\", text)\n",
    "\ttext = re.sub(r\"how\\'d'y\", \" how do you\", text)\n",
    "\ttext = re.sub(r\"how\\'ll\", \" how will\", text)\n",
    "\ttext = re.sub(r\"how\\'s\", \" how is\", text)\n",
    "\ttext = re.sub(r\"how\\'d\", \" how did\", text)\n",
    "\ttext = re.sub(r\"i\\'d\", \" i had\", text)\n",
    "\ttext = re.sub(r\"i\\'d've\", \" i would have\", text)\n",
    "\ttext = re.sub(r\"i\\'ll\", \" i will\", text)\n",
    "\ttext = re.sub(r\"i\\'ll've\", \" i will have\", text)\n",
    "\ttext = re.sub(r\"i\\'m\", \" i am\", text)\n",
    "\ttext = re.sub(r\"i\\'ve\", \" i have\", text)\n",
    "\ttext = re.sub(r\"i\\'ll\", \" i will\", text)\n",
    "\ttext = re.sub(r\"isn\\'t\", \" is not\", text)\n",
    "\ttext = re.sub(r\"it\\'d\", \" it had\", text)\n",
    "\ttext = re.sub(r\"it\\'d've\", \" it would have\", text)\n",
    "\ttext = re.sub(r\"it\\'ll\", \" it will\", text)\n",
    "\ttext = re.sub(r\"it\\'ll've\", \" it will have\", text)\n",
    "\ttext = re.sub(r\"it\\'s\", \" it is\", text)\n",
    "\ttext = re.sub(r\"let\\'s\", \" let us\", text)\n",
    "\ttext = re.sub(r\"ma\\'am\", \" madam\", text)\n",
    "\ttext = re.sub(r\"mayn\\'t\", \" may not\", text)\n",
    "\ttext = re.sub(r\"might\\'ve\", \" might have\", text)\n",
    "\ttext = re.sub(r\"mightn\\'t\", \" might not\", text)\n",
    "\ttext = re.sub(r\"mightn\\'t've\", \" might not have\", text)\n",
    "\ttext = re.sub(r\"mightn\\'t\", \" might not\", text)\n",
    "\ttext = re.sub(r\"must\\'ve\", \" must have\", text)\n",
    "\ttext = re.sub(r\"mustn\\'t\", \" must not\", text)\n",
    "\ttext = re.sub(r\"mustn\\'t've\", \" must not have\", text)\n",
    "\ttext = re.sub(r\"needn\\'t\", \" need not\", text)\n",
    "\ttext = re.sub(r\"needn\\'t've\", \" need not have\", text)\n",
    "\ttext = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
    "\ttext = re.sub(r\"oughtn\\'t\", \" ought not\", text)\n",
    "\ttext = re.sub(r\"oughtn\\'t've\", \" ought not have\", text)\n",
    "\ttext = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
    "\ttext = re.sub(r\"sha\\'n't\", \" shall not\", text)\n",
    "\ttext = re.sub(r\"shan\\'t've\", \" shall not have\", text)\n",
    "\ttext = re.sub(r\"she\\'d\", \" she had\", text)\n",
    "\ttext = re.sub(r\"she\\'d've\", \" she would have\", text)\n",
    "\ttext = re.sub(r\"she\\'ll\", \" she will\", text)\n",
    "\ttext = re.sub(r\"she\\'ll've\", \" she will have\", text)\n",
    "\ttext = re.sub(r\"she\\'s\", \" she is\", text)\n",
    "\ttext = re.sub(r\"should\\'ve\", \" should have\", text)\n",
    "\ttext = re.sub(r\"shouldn\\'t\", \" should not\", text)\n",
    "\ttext = re.sub(r\"shouldn\\'t've\", \" should not have\", text)\n",
    "\ttext = re.sub(r\"so\\'ve\", \" so have\", text)\n",
    "\ttext = re.sub(r\"so\\'s\", \" so is\", text)\n",
    "\ttext = re.sub(r\"that\\'d\", \" that would\", text)\n",
    "\ttext = re.sub(r\"that\\'d've\", \" that would have\", text)\n",
    "\ttext = re.sub(r\"that\\'s\", \" that is\", text)\n",
    "\ttext = re.sub(r\"there\\'d\", \" there had\", text)\n",
    "\ttext = re.sub(r\"there\\'d've\", \" there would have\", text)\n",
    "\ttext = re.sub(r\"there\\'s\", \" there is\", text)\n",
    "\ttext = re.sub(r\"they\\'d\", \" they had\", text)\n",
    "\ttext = re.sub(r\"they\\'d've\", \" they would have\", text)\n",
    "\ttext = re.sub(r\"they\\'ll\", \" they will\", text)\n",
    "\ttext = re.sub(r\"they\\'ll've\", \" they will have\", text)\n",
    "\ttext = re.sub(r\"they\\'re\", \" they are\", text)\n",
    "\ttext = re.sub(r\"they\\'ve\", \" they have\", text)\n",
    "\ttext = re.sub(r\"to\\'ve\", \" to have\", text)\n",
    "\ttext = re.sub(r\"wasn\\'t\", \" was not\", text)\n",
    "\ttext = re.sub(r\"we\\'d\", \" we had\", text)\n",
    "\ttext = re.sub(r\"we\\'d\\'ve\", \" we would have\", text)\n",
    "\ttext = re.sub(r\"we\\'ll\", \" we will\", text)\n",
    "\ttext = re.sub(r\"we\\'ll\\'ve\", \" we will have\", text)\n",
    "\ttext = re.sub(r\"we\\'re\", \" we are\", text)\n",
    "\ttext = re.sub(r\"we\\'ve\", \" we have\", text)\n",
    "\ttext = re.sub(r\"weren\\'t\", \" were not\", text)\n",
    "\ttext = re.sub(r\"what\\'ll\", \" what will\", text)\n",
    "\ttext = re.sub(r\"what\\'ll\\'ve\", \" what will have\", text)\n",
    "\ttext = re.sub(r\"what\\'re\", \" what are\", text)\n",
    "\ttext = re.sub(r\"what\\'s\", \" what is\", text)\n",
    "\ttext = re.sub(r\"what\\'ve\", \" what have\", text)\n",
    "\ttext = re.sub(r\"when\\'s\", \" when is\", text)\n",
    "\ttext = re.sub(r\"when\\'ve\", \" when have\", text)\n",
    "\ttext = re.sub(r\"where\\'d\", \" where did\", text)\n",
    "\ttext = re.sub(r\"where\\'s\", \" where is\", text)\n",
    "\ttext = re.sub(r\"where\\'ve\", \" where have\", text)\n",
    "\ttext = re.sub(r\"who\\'ll\", \" who will\", text)\n",
    "\ttext = re.sub(r\"who\\'ll\\'ve\", \" who will have\", text)\n",
    "\ttext = re.sub(r\"who\\'s\", \" who is\", text)\n",
    "\ttext = re.sub(r\"who\\'ve\", \" who have\", text)\n",
    "\ttext = re.sub(r\"why\\'s\", \" why is\", text)\n",
    "\ttext = re.sub(r\"why\\'ve\", \" why have\", text)\n",
    "\ttext = re.sub(r\"will\\'ve\", \" will have\", text)\n",
    "\ttext = re.sub(r\"won\\'t\", \" will not\", text)\n",
    "\ttext = re.sub(r\"won\\'t\\'ve\", \" will not have\", text)\n",
    "\ttext = re.sub(r\"would\\'ve\", \" would have\", text)\n",
    "\ttext = re.sub(r\"wouldn\\'t\", \" would not\", text)\n",
    "\ttext = re.sub(r\"wouldn\\'t\\'ve\", \" would not have\", text)\n",
    "\ttext = re.sub(r\"y\\'all\", \" you all\", text)\n",
    "\ttext = re.sub(r\"y\\'all\\'d\\'ve\", \" you all would have\", text)\n",
    "\ttext = re.sub(r\"y\\'all\\'d\\'ve\", \" you all would have\", text)\n",
    "\ttext = re.sub(r\"y\\'all\\'re\", \" you all are\", text)\n",
    "\ttext = re.sub(r\"y\\'all\\'ve\", \" you all have\", text)\n",
    "\ttext = re.sub(r\"you\\'d\\'ve\", \" you would have\", text)\n",
    "\ttext = re.sub(r\"you\\'ll\", \" you will\", text)\n",
    "\ttext = re.sub(r\"you\\'ll\\'ve\", \" you will have\", text)\n",
    "\ttext = re.sub(r\"you\\'re\", \" you are\", text)\n",
    "\ttext = re.sub(r\"you\\'ve\", \" you have\", text)\n",
    " \n",
    "\t# Eliminar espacios en blanco\n",
    "\ttext = re.sub(r'\\s{2,}', ' ', text)\n",
    " \n",
    "\t# Eliminar stopwords\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttext = text.split()\n",
    "\ttext = [w for w in text if not w in stop_words]\n",
    "\ttext = \" \".join(text)\n",
    " \n",
    "\t# Stemming\n",
    "\ttext = text.split()\n",
    "\tstemmer = SnowballStemmer('english')\n",
    "\tstemmed_words = [stemmer.stem(word) for word in text]\n",
    "\ttext = \" \".join(stemmed_words)\n",
    " \t\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto limpio en un nuevo dataframe\n",
    "df_clean = pd.DataFrame()\n",
    "\n",
    "# Limpiamos el texto\n",
    "df_clean['text'] = df['text'].apply(clean_text)\n",
    "df_clean['label'] = df['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamos las noticias limpias en un nuevo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../data/train_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
